<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://zatoima.github.io/images/favicon.png" />
<title>EMR PySparkにspark-submitで実行 | my opinion is my own</title>
<meta name="title" content="EMR PySparkにspark-submitで実行" />
<meta name="description" content="" />
<meta name="keywords" content="AWS,EMR," />


<meta property="og:url" content="https://zatoima.github.io/aws-emr-pyspark-spark-submit-command.html">
  <meta property="og:site_name" content="my opinion is my own">
  <meta property="og:title" content="EMR PySparkにspark-submitで実行">
  <meta property="og:description" content="memo blog">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2021-09-18T00:00:00+00:00">
    <meta property="article:modified_time" content="2021-09-18T00:00:00+00:00">
    <meta property="article:tag" content="AWS">
    <meta property="article:tag" content="EMR">
    <meta property="og:image" content="https://zatoima.github.io/images/share.png">



<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://zatoima.github.io/images/share.png"><meta name="twitter:title" content="EMR PySparkにspark-submitで実行">
<meta name="twitter:description" content="">




  <meta itemprop="name" content="EMR PySparkにspark-submitで実行">
  <meta itemprop="description" content="memo blog">
  <meta itemprop="datePublished" content="2021-09-18T00:00:00+00:00">
  <meta itemprop="dateModified" content="2021-09-18T00:00:00+00:00">
  <meta itemprop="wordCount" content="655">
  <meta itemprop="image" content="https://zatoima.github.io/images/share.png">
  <meta itemprop="keywords" content="AWS,EMR">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-STFZ9QMXGM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-STFZ9QMXGM');
</script>
</head>

<body>
  <header><a href="/" class="title">
  <h2>my opinion is my own</h2>
</a>
<nav>
<a href="/about/">About</a>
<a href="/blog/">Blog</a>
<a href="/index.xml">RSS</a>
<a href="/other/">Other</a>
</nav>
</header>
  <main>
<h1>EMR PySparkにspark-submitで実行</h1>

<p>
  <i>
    <time datetime='2021-09-18' pubdate>
      2021-09-18
    </time>
  </i>
</p>

<content>
  <h3 id="実行用ファイル作成">実行用ファイル作成</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>vi test.py
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql.types <span style="color:#f92672">import</span> <span style="color:#f92672">*</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.context <span style="color:#f92672">import</span> SparkContext
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pyspark.sql.session <span style="color:#f92672">import</span> SparkSession
</span></span><span style="display:flex;"><span>sc <span style="color:#f92672">=</span> SparkContext(<span style="color:#e6db74">&#39;local&#39;</span>)
</span></span><span style="display:flex;"><span>spark <span style="color:#f92672">=</span> SparkSession(sc)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">test_pyspark_sql</span>():
</span></span><span style="display:flex;"><span>    schema <span style="color:#f92672">=</span> StructType([
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;file&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;num&#39;</span>, IntegerType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;row&#39;</span>, IntegerType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;word&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;subtype1&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;subtype2&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;subtype3&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;subtype4&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;conjtype&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;conjugation&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;basic&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;ruby&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>            StructField(<span style="color:#e6db74">&#39;pronunce&#39;</span>, StringType(), <span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>         ]) 
</span></span><span style="display:flex;"><span>    df <span style="color:#f92672">=</span> spark<span style="color:#f92672">.</span>read<span style="color:#f92672">.</span>csv(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;s3://sparkwdcnt/utf8_all.csv&#39;</span>, schema<span style="color:#f92672">=</span>schema, header<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    df<span style="color:#f92672">.</span>groupBy(<span style="color:#e6db74">&#39;word&#39;</span>)<span style="color:#f92672">.</span>count()<span style="color:#f92672">.</span>sort(<span style="color:#e6db74">&#39;count&#39;</span>, ascending<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)<span style="color:#f92672">.</span>show(<span style="color:#ae81ff">30</span>)
</span></span><span style="display:flex;"><span>    df<span style="color:#f92672">.</span>write<span style="color:#f92672">.</span>mode(<span style="color:#e6db74">&#34;overwrite&#34;</span>)<span style="color:#f92672">.</span>option(<span style="color:#e6db74">&#34;header&#34;</span>, <span style="color:#e6db74">&#34;True&#34;</span>)<span style="color:#f92672">.</span>csv(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;s3://sparkwdcnt/utf8_all_count.csv&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:	
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;test Start&#34;</span>)
</span></span><span style="display:flex;"><span>    test_pyspark_sql()	
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;test end&#34;</span>)
</span></span></code></pre></div><h3 id="実行">実行</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>spark-submit --class org.apache.spark.examples.SparkPi /home/hadoop/test.py
</span></span></code></pre></div><h3 id="spark-submitのオプション">spark-submitのオプション</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">[</span>hadoop@ip-172-31-2-204 ~<span style="color:#f92672">]</span>$ spark-submit --help
</span></span><span style="display:flex;"><span>Usage: spark-submit <span style="color:#f92672">[</span>options<span style="color:#f92672">]</span> &lt;app jar | python file | R file&gt; <span style="color:#f92672">[</span>app arguments<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Usage: spark-submit --kill <span style="color:#f92672">[</span>submission ID<span style="color:#f92672">]</span> --master <span style="color:#f92672">[</span>spark://...<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Usage: spark-submit --status <span style="color:#f92672">[</span>submission ID<span style="color:#f92672">]</span> --master <span style="color:#f92672">[</span>spark://...<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>Usage: spark-submit run-example <span style="color:#f92672">[</span>options<span style="color:#f92672">]</span> example-class <span style="color:#f92672">[</span>example args<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Options:
</span></span><span style="display:flex;"><span>  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,
</span></span><span style="display:flex;"><span>                              k8s://https://host:port, or local <span style="color:#f92672">(</span>Default: local<span style="color:#f92672">[</span>*<span style="color:#f92672">])</span>.
</span></span><span style="display:flex;"><span>  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally <span style="color:#f92672">(</span><span style="color:#e6db74">&#34;client&#34;</span><span style="color:#f92672">)</span> or
</span></span><span style="display:flex;"><span>                              on one of the worker machines inside the cluster <span style="color:#f92672">(</span><span style="color:#e6db74">&#34;cluster&#34;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>                              <span style="color:#f92672">(</span>Default: client<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>  --class CLASS_NAME          Your application<span style="color:#960050;background-color:#1e0010">&#39;</span>s main class <span style="color:#f92672">(</span><span style="color:#66d9ef">for</span> Java / Scala apps<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>  --name NAME                 A name of your application.
</span></span><span style="display:flex;"><span>  --jars JARS                 Comma-separated list of jars to include on the driver
</span></span><span style="display:flex;"><span>                              and executor classpaths.
</span></span><span style="display:flex;"><span>  --packages                  Comma-separated list of maven coordinates of jars to include
</span></span><span style="display:flex;"><span>                              on the driver and executor classpaths. Will search the local
</span></span><span style="display:flex;"><span>                              maven repo, <span style="color:#66d9ef">then</span> maven central and any additional remote
</span></span><span style="display:flex;"><span>                              repositories given by --repositories. The format <span style="color:#66d9ef">for</span> the
</span></span><span style="display:flex;"><span>                              coordinates should be groupId:artifactId:version.
</span></span><span style="display:flex;"><span>  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude <span style="color:#66d9ef">while</span>
</span></span><span style="display:flex;"><span>                              resolving the dependencies provided in --packages to avoid
</span></span><span style="display:flex;"><span>                              dependency conflicts.
</span></span><span style="display:flex;"><span>  --repositories              Comma-separated list of additional remote repositories to
</span></span><span style="display:flex;"><span>                              search <span style="color:#66d9ef">for</span> the maven coordinates given with --packages.
</span></span><span style="display:flex;"><span>  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place
</span></span><span style="display:flex;"><span>                              on the PYTHONPATH <span style="color:#66d9ef">for</span> Python apps.
</span></span><span style="display:flex;"><span>  --files FILES               Comma-separated list of files to be placed in the working
</span></span><span style="display:flex;"><span>                              directory of each executor. File paths of these files
</span></span><span style="display:flex;"><span>                              in executors can be accessed via SparkFiles.get<span style="color:#f92672">(</span>fileName<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  --conf, -c PROP<span style="color:#f92672">=</span>VALUE       Arbitrary Spark configuration property.
</span></span><span style="display:flex;"><span>  --properties-file FILE      Path to a file from which to load extra properties. If not
</span></span><span style="display:flex;"><span>                              specified, this will look <span style="color:#66d9ef">for</span> conf/spark-defaults.conf.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  --driver-memory MEM         Memory <span style="color:#66d9ef">for</span> driver <span style="color:#f92672">(</span>e.g. 1000M, 2G<span style="color:#f92672">)</span> <span style="color:#f92672">(</span>Default: 1024M<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>  --driver-java-options       Extra Java options to pass to the driver.
</span></span><span style="display:flex;"><span>  --driver-library-path       Extra library path entries to pass to the driver.
</span></span><span style="display:flex;"><span>  --driver-class-path         Extra class path entries to pass to the driver. Note that
</span></span><span style="display:flex;"><span>                              jars added with --jars are automatically included in the
</span></span><span style="display:flex;"><span>                              classpath.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  --executor-memory MEM       Memory per executor <span style="color:#f92672">(</span>e.g. 1000M, 2G<span style="color:#f92672">)</span> <span style="color:#f92672">(</span>Default: 1G<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  --proxy-user NAME           User to impersonate when submitting the application.
</span></span><span style="display:flex;"><span>                              This argument does not work with --principal / --keytab.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  --help, -h                  Show this help message and exit.
</span></span><span style="display:flex;"><span>  --verbose, -v               Print additional debug output.
</span></span><span style="display:flex;"><span>  --version,                  Print the version of current Spark.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Cluster deploy mode only:
</span></span><span style="display:flex;"><span>  --driver-cores NUM          Number of cores used by the driver, only in cluster mode
</span></span><span style="display:flex;"><span>                              <span style="color:#f92672">(</span>Default: 1<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Spark standalone or Mesos with cluster deploy mode only:
</span></span><span style="display:flex;"><span>  --supervise                 If given, restarts the driver on failure.
</span></span><span style="display:flex;"><span>  --kill SUBMISSION_ID        If given, kills the driver specified.
</span></span><span style="display:flex;"><span>  --status SUBMISSION_ID      If given, requests the status of the driver specified.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Spark standalone and Mesos only:
</span></span><span style="display:flex;"><span>  --total-executor-cores NUM  Total cores <span style="color:#66d9ef">for</span> all executors.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Spark standalone and YARN only:
</span></span><span style="display:flex;"><span>  --executor-cores NUM        Number of cores per executor. <span style="color:#f92672">(</span>Default: <span style="color:#ae81ff">1</span> in YARN mode,
</span></span><span style="display:flex;"><span>                              or all available cores on the worker in standalone mode<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> YARN-only:
</span></span><span style="display:flex;"><span>  --queue QUEUE_NAME          The YARN queue to submit to <span style="color:#f92672">(</span>Default: <span style="color:#e6db74">&#34;default&#34;</span><span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>  --num-executors NUM         Number of executors to launch <span style="color:#f92672">(</span>Default: 2<span style="color:#f92672">)</span>.
</span></span><span style="display:flex;"><span>                              If dynamic allocation is enabled, the initial number of
</span></span><span style="display:flex;"><span>                              executors will be at least NUM.
</span></span><span style="display:flex;"><span>  --archives ARCHIVES         Comma separated list of archives to be extracted into the
</span></span><span style="display:flex;"><span>                              working directory of each executor.
</span></span><span style="display:flex;"><span>  --principal PRINCIPAL       Principal to be used to login to KDC, <span style="color:#66d9ef">while</span> running on
</span></span><span style="display:flex;"><span>                              secure HDFS.
</span></span><span style="display:flex;"><span>  --keytab KEYTAB             The full path to the file that contains the keytab <span style="color:#66d9ef">for</span> the
</span></span><span style="display:flex;"><span>                              principal specified above. This keytab will be copied to
</span></span><span style="display:flex;"><span>                              the node running the Application Master via the Secure
</span></span><span style="display:flex;"><span>                              Distributed Cache, <span style="color:#66d9ef">for</span> renewing the login tickets and the
</span></span><span style="display:flex;"><span>                              delegation tokens periodically.
</span></span><span style="display:flex;"><span>      
</span></span></code></pre></div><h3 id="参考">参考</h3>
<blockquote>
<p>Submitting Applications - Spark 3.1.1 Documentation <a href="https://spark.apache.org/docs/latest/submitting-applications.html">https://spark.apache.org/docs/latest/submitting-applications.html</a></p>
</blockquote>

</content>
---

<p>関連しているかもしれない記事</p>
 
<ul>
  
  <li><a href="/aws-emr-spark-python-wordcount/">EMR PySparkでWordCount</a></li>
  
  <li><a href="/aws-emr-spark-concept-component.html">Apache Sparkの構成要素、概要、用語について</a></li>
  
  <li><a href="/aws-emr-web-ui-tool-ssh-tunnel-browser.html">Amazon EMRのWebツール（Gangliaなど）をSSHトンネルを使ってブラウザ表示</a></li>
  
  <li><a href="/aws-emr-spark-python-udf-performance/">PySparkでUDFを使用する場合の性能面の注意点</a></li>
  
  <li><a href="/aws-emr-error-log-s3-command.html">EMRのエラーをS3のログから確認</a></li>
  
</ul>

<br>

<p>
  
  <a href="https://zatoima.github.io/blog/aws/">#AWS</a>
  
  <a href="https://zatoima.github.io/blog/emr/">#EMR</a>
  
</p>


  </main>
  <footer>Made with <a href="https://github.com/janraasch/hugo-bearblog/">Hugo ʕ•ᴥ•ʔ Bear</a>
</footer>

    
</body>

</html>
