<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="https://zatoima.github.io/favicon.svg" />
<title>LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰ | my opinion is my own</title>
<meta name="title" content="LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰" />
<meta name="description" content="" />
<meta name="keywords" content="LLM,AI,è«–æ–‡," />


<meta property="og:url" content="https://zatoima.github.io/llm-papers-2026-02-23/">
  <meta property="og:site_name" content="my opinion is my own">
  <meta property="og:title" content="LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰">
  <meta property="og:description" content="memo blog. Hugo on GitHub Pages">
  <meta property="og:locale" content="ja">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2026-02-23T00:00:00+00:00">
    <meta property="article:modified_time" content="2026-02-23T00:00:00+00:00">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="è«–æ–‡">
    <meta property="og:image" content="https://zatoima.github.io/images/share.png">




  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://zatoima.github.io/images/share.png">
  <meta name="twitter:title" content="LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰">
  <meta name="twitter:description" content="memo blog. Hugo on GitHub Pages">




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "\"LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰\"",
  "description": "\"\"",
  "datePublished": "\"2026-02-23T00:00:00Z\"",
  "dateModified": "\"2026-02-23T00:00:00Z\"",
  "author": {
    "@type": "Person",
    "name": "\"zatoima\"",
    "url": "https://zatoima.github.io/about/"
  },
  "publisher": {
    "@type": "Person",
    "name": "\"zatoima\""
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "\"https://zatoima.github.io/llm-papers-2026-02-23/\""
  },
  "inLanguage": "ja",
  "wordCount":  2981 ,
  "keywords": "[\"LLM\",\"AI\",\"è«–æ–‡\"]"
}
</script>

<meta name="referrer" content="no-referrer-when-downgrade" />

  <link rel="alternate" type="text/plain" href="/llms.txt" title="LLMs.txt" />
  <link rel="alternate" type="text/plain" href="/llms-full.txt" title="LLMs-full.txt" />

  <script>
    (function(){
      var t = localStorage.getItem('theme');
      if (t === 'dark' || ((!t || t === 'system') && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
        document.documentElement.setAttribute('data-theme', 'dark');
      }
    })();
  </script><link rel="stylesheet" href="/css/zenn.css">

<script async src="https://www.googletagmanager.com/gtag/js?id=G-STFZ9QMXGM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-STFZ9QMXGM');
</script>

</head>

<body>
  <a href="#main" class="skip-link">ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¸ã‚¹ã‚­ãƒƒãƒ—</a>
  <div class="reading-progress"></div>
  
  
  <div class="site-wrapper">
    <header class="site-header">
      <div class="header-inner">
        <a href="/" class="site-logo">my opinion is my own</a>
        <nav class="header-nav">
<a href="/about/">About</a>
<a href="/blog/">Blog</a>
<a href="/index.xml">RSS</a>
<a href="/other/">Other</a>
<a href="/llms.txt" title="LLMs.txt - AI/LLMå‘ã‘ã‚µã‚¤ãƒˆæƒ…å ±">llms.txt</a>
</nav>
        <div class="header-actions">
          <button id="search-btn" class="header-icon-btn" aria-label="æ¤œç´¢">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><path d="m21 21-4.3-4.3"/></svg>
          </button>
          <button id="dark-mode-btn" class="header-icon-btn" aria-label="ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿" data-label-light="ãƒ©ã‚¤ãƒˆ" data-label-dark="ãƒ€ãƒ¼ã‚¯" data-label-system="ã‚·ã‚¹ãƒ†ãƒ ">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg>
          </button><div class="lang-switcher">
  <button id="lang-btn" class="header-icon-btn" aria-label="è¨€èªã‚’åˆ‡ã‚Šæ›¿ãˆ">
    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"/><line x1="2" y1="12" x2="22" y2="12"/><path d="M12 2a15.3 15.3 0 0 1 4 10 15.3 15.3 0 0 1-4 10 15.3 15.3 0 0 1-4-10 15.3 15.3 0 0 1 4-10z"/></svg>
  </button>
  <div id="lang-dropdown" class="lang-dropdown">
    
    <a href="https://zatoima.github.io/" class="lang-dropdown-item active" lang="ja">
      æ—¥æœ¬èª
    </a>
    
    <a href="https://zatoima.github.io/en/" class="lang-dropdown-item" lang="en">
      English
    </a>
    
  </div>
</div>
<button id="hamburger-btn" class="hamburger-btn" aria-label="ãƒ¡ãƒ‹ãƒ¥ãƒ¼">
            <span></span><span></span><span></span>
          </button>
        </div>
      </div>
    </header>

    
    <div id="search-overlay" class="search-overlay">
      <div class="search-modal">
        <input type="text" id="search-input" class="search-input" placeholder="è¨˜äº‹ã‚’æ¤œç´¢... (Ctrl&#43;K)" autocomplete="off" data-min-chars="2æ–‡å­—ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„" data-no-results="è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ">
        <div id="search-results" class="search-results"></div>
      </div>
    </div>

    
    <div id="nav-overlay" class="nav-overlay"></div>

    <main id="main" class="site-main">
<div class="article-layout">
  <article class="article-main">
    
    <nav class="breadcrumb" aria-label="ãƒ‘ãƒ³ããšãƒªã‚¹ãƒˆ">
  <a href="/">ãƒ›ãƒ¼ãƒ </a>
  <span class="breadcrumb-sep">&gt;</span>
  
  <a href="/blog/">Blog</a>
  <span class="breadcrumb-sep">&gt;</span>
  
  <span class="breadcrumb-current">LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰</span>
</nav>

    
    <div class="article-card">
      <div class="article-header">
        <div class="article-emoji"><img src="/images/tags/llm.svg" alt="LLM" class="tag-icon" loading="lazy"></div>
        <h1>LLMè«–æ–‡ã‚µãƒ¼ãƒ™ã‚¤ï¼ˆ2026-02-23ï¼‰</h1>
        
        <div class="article-meta">
          <time class="article-date" datetime='2026-02-23'>
            ã«å…¬é–‹ 2026/02/23
          </time>
          
          
          
          <span class="reading-time">ğŸ“– ç´„5åˆ†</span>
        </div>
        <div class="article-tags">
          
          <a href="https://zatoima.github.io/blog/llm/" class="tag-badge"><img src="/images/tags/llm.svg" alt="LLM" class="tag-badge-icon" loading="lazy">LLM</a>
          
          <a href="https://zatoima.github.io/blog/ai/" class="tag-badge"><img src="/images/tags/ai.svg" alt="AI" class="tag-badge-icon" loading="lazy">AI</a>
          
          <a href="https://zatoima.github.io/blog/%E8%AB%96%E6%96%87/" class="tag-badge">è«–æ–‡</a>
          
        </div>
        
      </div>
      <div class="article-content">
        <h2 id="ã¯ã˜ã‚ã«">ã¯ã˜ã‚ã«</h2>
<p>æœ¬è¨˜äº‹ã¯2026-02-23æ™‚ç‚¹ã§ã®LLMé–¢é€£ã®æ³¨ç›®è«–æ–‡ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚arXivã€Semantic Scholarã€Hugging Face Daily Papersã‹ã‚‰è‡ªå‹•åé›†ã—ã€Claude APIã§æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚</p>
<h2 id="1-vespo-variational-sequence-level-soft-policy-optimization-for-stable-off-policy-llm-training">1. VESPO: Variational Sequence-Level Soft Policy Optimization for Stable Off-Policy LLM Training</h2>
<ul>
<li><strong>è‘—è€…</strong>: Guobin Shen, Chenxiao Zhao, Xiang Cheng, Lei Huang, Xing Yu</li>
<li><strong>å…¬é–‹æ—¥</strong>: 2026-02-11</li>
<li><strong>ã‚½ãƒ¼ã‚¹</strong>: <a href="https://arxiv.org/abs/2602.10693" target="_blank" rel="noopener noreferrer">huggingface</a>
</li>
<li><strong>arXiv ID</strong>: 2602.10693</li>
</ul>
<h3 id="è¦ç´„">è¦ç´„</h3>
<p>å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹è¨“ç·´å®‰å®šæ€§ã®èª²é¡Œã«å–ã‚Šçµ„ã‚“ã ç ”ç©¶ã§ã‚ã‚‹ã€‚ãƒãƒªã‚·ãƒ¼ã®é™³è…åŒ–ã‚„éåŒæœŸè¨“ç·´ã€è¨“ç·´ã‚¨ãƒ³ã‚¸ãƒ³ã¨æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®ä¸ä¸€è‡´ã«ã‚ˆã‚Šè¡Œå‹•ãƒãƒªã‚·ãƒ¼ãŒç¾è¡Œãƒãƒªã‚·ãƒ¼ã‹ã‚‰ä¹–é›¢ã—ã€è¨“ç·´å´©å£Šã‚’å¼•ãèµ·ã“ã™ãƒªã‚¹ã‚¯ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ææ¡ˆåˆ†å¸ƒã«å¯¾ã™ã‚‹å¤‰åˆ†å®šå¼åŒ–ã«åˆ†æ•£å‰Šæ¸›ã‚’çµ„ã¿è¾¼ã‚“ã VESPOï¼ˆVariational sEquence-level Soft Policy Optimizationï¼‰ã‚’ææ¡ˆã—ã€é•·ã•æ­£è¦åŒ–ã‚’å¿…è¦ã¨ã›ãšã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®é‡è¦åº¦é‡ã¿ã«ç›´æ¥ä½œç”¨ã™ã‚‹é–‰å½¢å¼ã®å†å½¢æˆã‚«ãƒ¼ãƒãƒ«ã‚’å°å‡ºã—ãŸã€‚æ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã‘ã‚‹å®Ÿé¨“ã§ã¯ã€VESPOã¯é™³è…åŒ–æ¯”ç‡64å€ãŠã‚ˆã³å®Œå…¨éåŒæœŸå®Ÿè¡Œä¸‹ã§ã‚‚å®‰å®šã—ãŸè¨“ç·´ã‚’ç¶­æŒã—ã€å¯†çµåˆãƒ¢ãƒ‡ãƒ«ã¨Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã§ä¸€è²«ã—ãŸæ€§èƒ½å‘ä¸Šã‚’é”æˆã—ãŸã€‚</p>
<details>
  <summary>åŸæ–‡Abstract</summary>
  <p>Training stability remains a central challenge in reinforcement learning (RL) for large language models (LLMs). Policy staleness, asynchronous training, and mismatches between training and inference engines all cause the behavior policy to diverge from the current policy, risking training collapse. Importance sampling provides a principled correction for this distribution shift but suffers from high variance; existing remedies such as token-level clipping and sequence-level normalization lack a unified theoretical foundation. We propose Variational sEquence-level Soft Policy Optimization (VESPO). By incorporating variance reduction into a variational formulation over proposal distributions, VESPO derives a closed-form reshaping kernel that operates directly on sequence-level importance weights without length normalization. Experiments on mathematical reasoning benchmarks show that VESPO maintains stable training under staleness ratios up to 64x and fully asynchronous execution, and delivers consistent gains across both dense and Mixture-of-Experts models. Code is available at <a href="https://github.com/FloyedShen/VESPO" target="_blank" rel="noopener noreferrer">https://github.com/FloyedShen/VESPO</a></p>
</details>
<h2 id="2-does-your-reasoning-model-implicitly-know-when-to-stop-thinking">2. Does Your Reasoning Model Implicitly Know When to Stop Thinking?</h2>
<ul>
<li><strong>è‘—è€…</strong>: Zixuan Huang, Xin Xia, Yuxi Ren, Jianbin Zheng, Xuanda Wang ã»ã‹</li>
<li><strong>å…¬é–‹æ—¥</strong>: 2026-02-09</li>
<li><strong>ã‚½ãƒ¼ã‚¹</strong>: <a href="https://arxiv.org/abs/2602.08354" target="_blank" rel="noopener noreferrer">huggingface</a>
</li>
<li><strong>arXiv ID</strong>: 2602.08354</li>
</ul>
<h3 id="è¦ç´„-1">è¦ç´„</h3>
<p>å¤§è¦æ¨¡æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆLRMï¼‰ã¯é•·ã„æ€è€ƒé€£é–ï¼ˆCoTï¼‰ã«ã‚ˆã‚Šè¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¦ããŸãŒã€å†—é•·ãªæ¨è«–ãŒè¨ˆç®—åŠ¹ç‡ã‚’æãªã„ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç”¨ã§ã®é…å»¶ã‚’å¼•ãèµ·ã“ã™ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚å…ˆè¡Œç ”ç©¶ã§ã¯ã€æ¨è«–é€£é–ãŒé•·ã„ã»ã©æ­£ç­”ç‡ãŒä¸ŠãŒã‚‹ã‚ã‘ã§ã¯ãªãã€ã‚€ã—ã‚ç²¾åº¦ã‚’ä½ä¸‹ã•ã›ã‚‹å ´åˆãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LRMãŒæ€è€ƒã‚’åœæ­¢ã™ã¹ãé©åˆ‡ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æš—é»™çš„ã«æŠŠæ¡ã—ã¦ã„ã‚‹ãŒã€ç¾è¡Œã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ãŒãã®èƒ½åŠ›ã‚’è¦†ã„éš ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ãƒ»å®Ÿè¨¼ã—ãŸã€‚ã“ã®çŸ¥è¦‹ã«åŸºã¥ãã€åŠ¹ç‡çš„ãªæ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™æ–°ãŸãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•SAGEï¼ˆSelf-Aware Guided Efficient Reasoningï¼‰ã‚’ææ¡ˆã—ã€ã•ã‚‰ã«SAGEã‚’ã‚°ãƒ«ãƒ¼ãƒ—ãƒ™ãƒ¼ã‚¹å¼·åŒ–å­¦ç¿’ã«çµ±åˆã—ãŸSAGE-RLã«ã‚ˆã‚Šã€è¤‡æ•°ã®æ•°å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦æ¨è«–ã®ç²¾åº¦ã¨åŠ¹ç‡ã®ä¸¡æ–¹ã‚’å¤§å¹…ã«æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<details>
  <summary>åŸæ–‡Abstract</summary>
  <p>Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.</p>
</details>
<h2 id="3-sla2-sparse-linear-attention-with-learnable-routing-and-qat">3. SLA2: Sparse-Linear Attention with Learnable Routing and QAT</h2>
<ul>
<li><strong>è‘—è€…</strong>: Jintao Zhang, Haoxu Wang, Kai Jiang, Kaiwen Zheng, Youhe Jiang ã»ã‹</li>
<li><strong>å…¬é–‹æ—¥</strong>: 2026-02-13</li>
<li><strong>ã‚½ãƒ¼ã‚¹</strong>: <a href="https://arxiv.org/abs/2602.12675" target="_blank" rel="noopener noreferrer">huggingface</a>
</li>
<li><strong>arXiv ID</strong>: 2602.12675</li>
</ul>
<h3 id="è¦ç´„-2">è¦ç´„</h3>
<p>Sparse-Linear Attentionï¼ˆSLAï¼‰ã¯ã‚¹ãƒ‘ãƒ¼ã‚¹æ³¨æ„ã¨ç·šå½¢æ³¨æ„ã‚’çµ„ã¿åˆã‚ã›ã¦æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’é«˜é€ŸåŒ–ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ãŒã€ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªåˆ†å‰²æ–¹å¼ãŒæœ€é©ã§ãªã„ç‚¹ã¨ã€SLAã®æ³¨æ„èª¤å·®ã«ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ»ç·šå½¢æ³¨æ„ã®ç›´æ¥åˆ†è§£ã¨ã®ä¸ä¸€è‡´ãŒå­˜åœ¨ã™ã‚‹ç‚¹ãŒèª²é¡Œã§ã‚ã£ãŸã€‚æœ¬è«–æ–‡ã§ææ¡ˆã™ã‚‹SLA2ã¯ã€å„æ³¨æ„è¨ˆç®—ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹ã¨ç·šå½¢ã®ã©ã¡ã‚‰ã§å‡¦ç†ã™ã‚‹ã‹ã‚’å‹•çš„ã«é¸æŠã™ã‚‹å­¦ç¿’å¯èƒ½ãªãƒ«ãƒ¼ã‚¿ãƒ¼ã€å­¦ç¿’å¯èƒ½ãªæ¯”ç‡ã§ã‚¹ãƒ‘ãƒ¼ã‚¹ã¨ç·šå½¢ã®æ³¨æ„åˆ†å²ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã‚ˆã‚Šå¿ å®Ÿãªå®šå¼åŒ–ã€ãŠã‚ˆã³é‡å­åŒ–èªè­˜ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹ä½ãƒ“ãƒƒãƒˆæ³¨æ„è¨­è¨ˆã®3ã¤ã‚’å°å…¥ã™ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€SLA2ã¯å‹•ç”»æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦97%ã®æ³¨æ„ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’é”æˆã—ã€ç”Ÿæˆå“è³ªã‚’ç¶­æŒã—ãªãŒã‚‰æ³¨æ„è¨ˆç®—ã§18.6å€ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ãŸã€‚</p>
<details>
  <summary>åŸæ–‡Abstract</summary>
  <p>Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition into sparse and linear attention. We propose SLA2, which introduces (I) a learnable router that dynamically selects whether each attention computation should use sparse or linear attention, (II) a more faithful and direct sparse-linear attention formulation that uses a learnable ratio to combine the sparse and linear attention branches, and (III) a sparse + low-bit attention design, where low-bit attention is introduced via quantization-aware fine-tuning to reduce quantization error. Experiments show that on video diffusion models, SLA2 can achieve 97% attention sparsity and deliver an 18.6x attention speedup while preserving generation quality.</p>
</details>
<h2 id="4-spargeattention2-trainable-sparse-attention-via-hybrid-top-ktop-p-masking-and-distillation-fine-tuning">4. SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning</h2>
<ul>
<li><strong>è‘—è€…</strong>: Jintao Zhang, Kai Jiang, Chendong Xiang, Weiqi Feng, Yuezhou Hu ã»ã‹</li>
<li><strong>å…¬é–‹æ—¥</strong>: 2026-02-13</li>
<li><strong>ã‚½ãƒ¼ã‚¹</strong>: <a href="https://arxiv.org/abs/2602.13515" target="_blank" rel="noopener noreferrer">huggingface</a>
</li>
<li><strong>arXiv ID</strong>: 2602.13515</li>
</ul>
<h3 id="è¦ç´„-3">è¦ç´„</h3>
<p>æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é«˜é€ŸåŒ–ã«å‘ã‘ãŸå­¦ç¿’å¯èƒ½ãªã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ‰‹æ³•SpargeAttention2ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚Top-kã¨Top-pã¨ã„ã†2ã¤ã®ä¸€èˆ¬çš„ãªãƒã‚¹ã‚­ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ãã‚Œãã‚Œã®å¤±æ•—ã‚±ãƒ¼ã‚¹ã‚’åˆ†æã—ã€ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒã‚¹ã‚­ãƒ³ã‚°ã«ã‚ˆã‚Šé«˜ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã§ã‚‚ãƒ­ãƒã‚¹ãƒˆãªãƒã‚¹ã‚­ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹ã€‚ã•ã‚‰ã«ã€æ‹¡æ•£æå¤±ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é™ç•Œã‚’æŒ‡æ‘˜ã—ã€è’¸ç•™ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç›®çš„é–¢æ•°ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ç”Ÿæˆå“è³ªã®ç¶­æŒã‚’å›³ã‚‹ã€‚å‹•ç”»æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“ã§ã¯ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§95%ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å‡¦ç†ã®16.2å€ã®é«˜é€ŸåŒ–ã‚’é”æˆã—ã¤ã¤ç”Ÿæˆå“è³ªã‚’ç¶­æŒã—ã€æ—¢å­˜ã®ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ‰‹æ³•ã‚’ä¸€è²«ã—ã¦ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</p>
<details>
  <summary>åŸæ–‡Abstract</summary>
  <p>Many training-free sparse attention methods are effective for accelerating diffusion models. Recently, several works suggest that making sparse attention trainable can further increase sparsity while preserving generation quality. We study three key questions: (1) when do the two common masking rules, i.e., Top-k and Top-p, fail, and how can we avoid these failures? (2) why can trainable sparse attention reach higher sparsity than training-free methods? (3) what are the limitations of fine-tuning sparse attention using the diffusion loss, and how can we address them? Based on this analysis, we propose SpargeAttention2, a trainable sparse attention method that achieves high sparsity without degrading generation quality. SpargeAttention2 includes (i) a hybrid masking rule that combines Top-k and Top-p for more robust masking at high sparsity, (ii) an efficient trainable sparse attention implementation, and (iii) a distillation-inspired fine-tuning objective to better preserve generation quality during fine-tuning using sparse attention. Experiments on video diffusion models show that SpargeAttention2 reaches 95% attention sparsity and a 16.2x attention speedup while maintaining generation quality, consistently outperforming prior sparse attention methods.</p>
</details>
<h2 id="5-mobile-agent-v35-multi-platform-fundamental-gui-agents">5. Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents</h2>
<ul>
<li><strong>è‘—è€…</strong>: Haiyang Xu, Xi Zhang, Haowei Liu, Junyang Wang, Zhaozai Zhu ã»ã‹</li>
<li><strong>å…¬é–‹æ—¥</strong>: 2026-02-15</li>
<li><strong>ã‚½ãƒ¼ã‚¹</strong>: <a href="https://arxiv.org/abs/2602.16855" target="_blank" rel="noopener noreferrer">huggingface</a>
</li>
<li><strong>arXiv ID</strong>: 2602.16855</li>
</ul>
<h3 id="è¦ç´„-4">è¦ç´„</h3>
<p>GUI-Owl-1.5ã¯ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãƒ»ãƒ¢ãƒã‚¤ãƒ«ãƒ»ãƒ–ãƒ©ã‚¦ã‚¶ãªã©è¤‡æ•°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«å¯¾å¿œã—ãŸãƒã‚¤ãƒ†ã‚£ãƒ–GUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€2Bã‹ã‚‰235Bã¾ã§ã®è¤‡æ•°ã‚µã‚¤ã‚ºã§instruct/thinkingã®ä¸¡ãƒãƒªã‚¢ãƒ³ãƒˆã‚’æä¾›ã—ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚¨ãƒƒã‚¸é€£æºã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã™ã‚‹ã€‚OSWorldï¼ˆ56.5ï¼‰ã€AndroidWorldï¼ˆ71.6ï¼‰ã€WebArenaï¼ˆ48.4ï¼‰ã€ScreenSpotProï¼ˆ80.3ï¼‰ãªã©20ä»¥ä¸Šã®GUIãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æœ€é«˜æ€§èƒ½ã‚’é”æˆã—ãŸã€‚ä¸»è¦ãªæŠ€è¡“é©æ–°ã¨ã—ã¦ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ©ã‚¤ãƒ›ã‚¤ãƒ¼ãƒ«ã€ãƒ„ãƒ¼ãƒ«/MCPåˆ©ç”¨ãƒ»è¨˜æ†¶ãƒ»ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé©å¿œã‚’å«ã‚€çµ±ä¸€çš„ãªæ€è€ƒåˆæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèƒ½åŠ›ã®å¼·åŒ–ã€ãã—ã¦ãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ é–“ã®ç«¶åˆã¨é•·æœŸã‚¿ã‚¹ã‚¯ã®ä½è¨“ç·´åŠ¹ç‡ã«å¯¾å‡¦ã™ã‚‹æ–°ã—ã„ç’°å¢ƒå¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ MRPOã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚</p>
<details>
  <summary>åŸæ–‡Abstract</summary>
  <p>The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves state-of-the-art results on more than 20+ GUI benchmarks on open-source models: (1) on GUI automation tasks, it obtains 56.5 on OSWorld, 71.6 on AndroidWorld, and 48.4 on WebArena; (2) on grounding tasks, it obtains 80.3 on ScreenSpotPro; (3) on tool-calling tasks, it obtains 47.6 on OSWorld-MCP, and 46.8 on MobileWorld; (4) on memory and knowledge tasks, it obtains 75.5 on GUI-Knowledge Bench. GUI-Owl-1.5 incorporates several key innovations: (1) Hybird Data Flywheel: we construct the data pipeline for UI understanding and trajectory generation based on a combination of simulated environments and cloud-based sandbox environments, in order to improve the efficiency and quality of data collection. (2) Unified Enhancement of Agent Capabilities: we use a unified thought-synthesis pipeline to enhance the model&rsquo;s reasoning capabilities, while placing particular emphasis on improving key agent abilities, including Tool/MCP use, memory and multi-agent adaptation; (3) Multi-platform Environment RL Scaling: We propose a new environment RL algorithm, MRPO, to address the challenges of multi-platform conflicts and the low training efficiency of long-horizon tasks. The GUI-Owl-1.5 models are open-sourced, and an online cloud-sandbox demo is available at <a href="https://github.com/X-PLUG/MobileAgent" target="_blank" rel="noopener noreferrer">https://github.com/X-PLUG/MobileAgent</a>
.</p>
</details>
<hr>
<p><em>ã“ã®è¨˜äº‹ã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã™ã€‚è«–æ–‡ã®è©³ç´°ã¯å„ã‚½ãƒ¼ã‚¹URLã‚’ã”å‚ç…§ãã ã•ã„ã€‚</em></p>

      </div>
    </div>

    
    
    
    <a href="https://github.com/zatoima/zatoima.github.io/edit/main/content/blog/2026-02-23-llm-papers-daily/index.md" target="_blank" rel="noopener noreferrer" class="github-edit-link">
      <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M11 4H4a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2v-7"/><path d="M18.5 2.5a2.121 2.121 0 0 1 3 3L12 15l-4 1 1-4 9.5-9.5z"/></svg>
      GitHubã§ç·¨é›†ã‚’ææ¡ˆ
    </a>
    
    

    
    
    <nav class="prev-next-nav">
      
      <a href="https://zatoima.github.io/snowflake-directory-table-integration/" class="prev-next-link prev-link">
        <span class="prev-next-label">â† å‰ã®è¨˜äº‹</span>
        <span class="prev-next-title">Snowflakeã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è‡ªå‹•æ›´æ–°</span>
      </a>
      
      
      <a href="https://zatoima.github.io/hugo-blog-mcp-server-llms-txt/" class="prev-next-link next-link">
        <span class="prev-next-label">æ¬¡ã®è¨˜äº‹ â†’</span>
        <span class="prev-next-title">Hugoè£½ãƒ–ãƒ­ã‚°ã«MCP Serverã¨llms.txtã‚’å®Ÿè£…ã™ã‚‹</span>
      </a>
      
    </nav>
    

    
<div class="share-buttons">
  <span class="share-label">å…±æœ‰:</span>
  <a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fzatoima.github.io%2fllm-papers-2026-02-23%2f&text=LLM%E8%AB%96%E6%96%87%E3%82%B5%E3%83%BC%E3%83%99%E3%82%A4%EF%BC%882026-02-23%EF%BC%89" target="_blank" rel="noopener noreferrer" class="share-btn share-twitter" aria-label="Xã§å…±æœ‰">
    <svg width="18" height="18" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
  </a>
  <a href="https://b.hatena.ne.jp/entry/https://zatoima.github.io/llm-papers-2026-02-23/" target="_blank" rel="noopener noreferrer" class="share-btn share-hatena" aria-label="ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ ">B!</a>
</div>






<div class="post-tags">
  
  <a href="https://zatoima.github.io/blog/llm/" class="tag-badge"><img src="/images/tags/llm.svg" alt="LLM" class="tag-badge-icon" loading="lazy">LLM</a>
  
  <a href="https://zatoima.github.io/blog/ai/" class="tag-badge"><img src="/images/tags/ai.svg" alt="AI" class="tag-badge-icon" loading="lazy">AI</a>
  
  <a href="https://zatoima.github.io/blog/%E8%AB%96%E6%96%87/" class="tag-badge">è«–æ–‡</a>
  
</div>


  </article>

  
  <aside class="article-sidebar">
    <div class="toc-container">
      <div class="toc-title">ç›®æ¬¡</div>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#ã¯ã˜ã‚ã«">ã¯ã˜ã‚ã«</a></li>
    <li><a href="#1-vespo-variational-sequence-level-soft-policy-optimization-for-stable-off-policy-llm-training">1. VESPO: Variational Sequence-Level Soft Policy Optimization for Stable Off-Policy LLM Training</a>
      <ul>
        <li><a href="#è¦ç´„">è¦ç´„</a></li>
      </ul>
    </li>
    <li><a href="#2-does-your-reasoning-model-implicitly-know-when-to-stop-thinking">2. Does Your Reasoning Model Implicitly Know When to Stop Thinking?</a>
      <ul>
        <li><a href="#è¦ç´„-1">è¦ç´„</a></li>
      </ul>
    </li>
    <li><a href="#3-sla2-sparse-linear-attention-with-learnable-routing-and-qat">3. SLA2: Sparse-Linear Attention with Learnable Routing and QAT</a>
      <ul>
        <li><a href="#è¦ç´„-2">è¦ç´„</a></li>
      </ul>
    </li>
    <li><a href="#4-spargeattention2-trainable-sparse-attention-via-hybrid-top-ktop-p-masking-and-distillation-fine-tuning">4. SpargeAttention2: Trainable Sparse Attention via Hybrid Top-k+Top-p Masking and Distillation Fine-Tuning</a>
      <ul>
        <li><a href="#è¦ç´„-3">è¦ç´„</a></li>
      </ul>
    </li>
    <li><a href="#5-mobile-agent-v35-multi-platform-fundamental-gui-agents">5. Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents</a>
      <ul>
        <li><a href="#è¦ç´„-4">è¦ç´„</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
  </aside>
  
</div>

    </main>

    <footer class="site-footer">
      <div class="footer-inner">
        <div class="footer-disclaimer">æœ¬ãƒ–ãƒ­ã‚°ã®å†…å®¹ã¯å€‹äººçš„ãªè¦‹è§£ã§ã‚ã‚Šã€æ‰€å±ã™ã‚‹ä¼æ¥­ãƒ»çµ„ç¹”ã®å…¬å¼ãªè¦‹è§£ã‚’ç¤ºã™ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</div>
        <div class="footer-links">
          <a href="/">ãƒ›ãƒ¼ãƒ </a>
          <a href="/blog/">è¨˜äº‹ä¸€è¦§</a>
          <a href="/tags/">ã‚¿ã‚°ä¸€è¦§</a>
          <a href="/about/">About</a>
        </div>
        <div class="footer-social">
          <a href="https://github.com/zatoima" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
            <svg width="18" height="18" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
          </a>
          <a href="https://x.com/zatoima1" target="_blank" rel="noopener noreferrer" aria-label="X (Twitter)">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
          </a>
          <a href="/index.xml" aria-label="RSS">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M6.18 15.64a2.18 2.18 0 0 1 2.18 2.18C8.36 19.01 7.38 20 6.18 20C5 20 4 19.01 4 17.82a2.18 2.18 0 0 1 2.18-2.18M4 4.44A15.56 15.56 0 0 1 19.56 20h-2.83A12.73 12.73 0 0 0 4 7.27V4.44m0 5.66a9.9 9.9 0 0 1 9.9 9.9h-2.83A7.07 7.07 0 0 0 4 12.93V10.1z"/></svg>
          </a>
        </div>
        <div class="footer-copyright">Copyright Â© 2019, zatoima.</div>
        <div class="footer-disclaimer">memo blog. Hugo on GitHub Pages</div>
        <div class="footer-disclaimer">æœ¬ãƒ–ãƒ­ã‚°ã®å†…å®¹ã¯å€‹äººçš„ãªè¦‹è§£ã§ã‚ã‚Šã€æ‰€å±ã™ã‚‹ä¼æ¥­ãƒ»çµ„ç¹”ã®å…¬å¼ãªè¦‹è§£ã‚’ç¤ºã™ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚</div>
      </div>
    </footer>
  </div>
  <script src="/js/lightbox.js" defer></script>
  <script src="/js/toc-highlight.js" defer></script>
  <script src="/js/code-copy.js" defer></script>
  <script src="/js/dark-mode.js" defer></script>
  <script src="/js/mobile-nav.js" defer></script>
  <script src="/js/search.js" defer></script>
  <script src="/js/reading-progress.js" defer></script>
  <script src="/js/lang-detect.js" defer></script>
  <script src="/js/lang-switcher.js" defer></script>
</body>

</html>
